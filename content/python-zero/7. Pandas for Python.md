---
title: Pandas
description: 这里是简介部分：Code编码简介
navigation:
index: 7
icon: i-ph-info-duotone
---

## 一、Pandas 简介

Pandas 是一个开源的数据分析和数据处理库，它是基于 Python 编程语言的。

Pandas 提供了易于使用的数据结构和数据分析工具，特别适用于处理结构化数据，如表格型数据（类似于Excel表格）。

Pandas 是数据科学和分析领域中常用的工具之一，它使得用户能够轻松地从各种数据源中导入数据，并对数据进行高效的操作和分析。

Pandas 提供了丰富的功能，包括：

- 数据清洗：处理缺失数据、重复数据等。
- 数据转换：改变数据的形状、结构或格式。
- 数据分析：进行统计分析、聚合、分组等。
- 数据可视化：通过整合 Matplotlib 和 Seaborn 等库，可以进行数据可视化。

## 二、Pandas 中的数据结构

Pandas 主要引入了两种新的数据结构：**DataFrame** 和 **Series**。

- **Series**： 类似于一维数组或列表，是由一组数据以及与之相关的数据标签（索引）构成。Series 可以看作是 DataFrame 中的一列，也可以是单独存在的一维数据结构。
- **DataFrame**： 类似于一个二维表格，它是 Pandas 中最重要的数据结构。DataFrame 可以看作是由多个 Series 按列排列构成的表格，它既有行索引也有列索引，因此可以方便地进行行列选择、过滤、合并等操作。

> [!Note]
> DataFrame 可视为由多个 Series 组成的数据结构

### 1. Pandas Series

Pandas `Series` 是一种灵活的、一维的带索引的数据结构，可以存储多种类型的数据（如整数、浮点数、字符串、时间戳等）。每个数据项都有一个与之相关联的标签（索引），类似于字典的键值对。`Series` 的主要特点包括：

- **一维数组结构**：`Series` 是一种一维数据结构，类似 NumPy 数组，但比数组更灵活。
- **索引功能**：每个数据项都有一个唯一的索引，索引可以是默认的整数值（如 0, 1, 2...），也可以是自定义的（如字符、日期等）。索引允许快速访问和切片。
- **数据类型灵活**：`Series` 支持各种数据类型，包括整数、浮点数、布尔值、字符串、时间戳等。
- **自动对齐操作**：在涉及多个 `Series` 对象的操作时，Pandas 会根据索引自动对齐数据。
- **处理缺失值**：`Series` 支持处理缺失值（通常用 `NaN` 表示），并能在计算时智能忽略缺失值。
- **不可变大小**：一旦 `Series` 创建后，其大小就固定了，但可以通过类似 `append` 和 `drop` 等方法生成一个新的对象以调整大小。

我们可以通过 `pd.Series()` 构造函数来创建一个 `Series` 对象，传入数据（如列表、NumPy 数组等）和一个可选的索引数组。

```python
# 构造函数及参数
pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)
```

参数说明：

- **`data`**：`Series` 的数据部分，可以是列表、数组、字典、标量值等。如果不提供此参数，将创建一个空的 `Series`。
- **`index`**：`Series` 的索引部分，用于标记每个数据项。可以是列表、数组或索引对象等。如果未指定，则默认生成从 0 开始的整数索引。
- **`dtype`**：指定 `Series` 的数据类型。支持 NumPy 数据类型，如 `np.int64`、`np.float64` 等。如果不指定，系统将根据输入数据自动推断类型。
- **`name`**：为 `Series` 对象指定一个名称。如果提供此参数，生成的 `Series` 将具有相应的名称。
- **`copy`**：是否复制数据。如果为 `True`，则会复制输入数据。默认值为 `False`，表示不复制。
- **`fastpath`**：是否启用快速路径。默认为 `False`。该参数一般用于内部优化，启用时可能提高性能。

![](http://szms-python-images.oss-cn-hangzhou.aliyuncs.com/Pandas/%E5%88%9B%E5%BB%BAseries%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.png)

以下是一个基本示例，展示如何使用列表创建一个 `Series`：

```python
import pandas as pd

# 创建一个 Series
data = pd.Series([100, 200, 300, 400])

# 输出 Series
print(data)
```

输出：

```shell
0    100
1    200
2    300
3    400
dtype: int64
```

在这个示例中，`Series` 自动使用从 0 开始的整数索引。我们可以通过索引值来访问特定的数据：

```python
print(data[1])  # 输出 200
```

另外，我们还可以通过自定义索引来创建 `Series`：

```python
import pandas as pd

# 创建一个带有自定义索引的 Series
data = pd.Series([100, 200, 300, 400], index=["A", "B", "C", "D"])

# 输出 Series
print(data)
```

输出：

```shell
A    100
B    200
C    300
D    400
dtype: int64
```

此时，索引为 `A`、`B`、`C` 和 `D`。我们可以使用索引值访问对应数据：

```python
print(data["A"])  # 输出 100
```

通过传递一个字典也可以创建 `Series`。字典的键将作为 `Series` 的索引，值将作为 `Series` 的数据：

```python
import pandas as pd

# 使用字典创建一个 Series
data_dict = {"A": 10, "B": 20, "C": 30, "D": 40}
data_series = pd.Series(data_dict)

# 输出 Series
print(data_series)
```

输出：

```shell
A    10
B    20
C    30
D    40
dtype: int64
```

如果不需要字典中的全部数据，在创建 `Series` 时还可以通过指定索引来选择字典中的部分数据：

```python
# 仅选择部分索引
partial_series = pd.Series(data_dict, index=["A", "C"])
print(partial_series)
```

输出：

```shell
A    10
C    30
dtype: int64
```

总之，Pandas `Series` 是一个非常灵活和强大的数据结构，适合处理带索引的一维数据。无论是简单的数据列表，还是通过字典、数组构造的复杂数据，`Series` 提供了强大的操作和检索功能，尤其适合处理具有标签数据的场景。

### 2. Pandas DataFrame

Pandas `DataFrame` 是一种二维、带有行和列标签的数据结构，类似于电子表格或 SQL 表。它既可以存储各种类型的数据（如整数、浮点数、字符串、时间戳等），也可以将不同类型的数据组合在一起进行处理。`DataFrame` 是 Pandas 库中最常用的数据结构之一，广泛应用于数据分析、清洗和操作。

`DataFrame` 的主要特点包括：

- **二维数据结构**：`DataFrame` 是一种表格型的数据结构，具有行和列两部分，支持多种数据类型。
- **灵活的行列索引**：行和列均有对应的标签（索引），支持自定义或自动生成的整数索引。索引可用于快速定位数据。
- **异构数据类型**：不同的列可以存储不同类型的数据（例如，一列可以是字符串，另一列可以是浮点数）。
- **自动对齐操作**：在涉及多个 `DataFrame` 对象的操作时，Pandas 会根据行和列的索引自动对齐数据。
- **缺失值处理**：`DataFrame` 支持缺失值，通常用 `NaN` 表示，并提供丰富的方法来处理缺失数据。
- **丰富的操作功能**：`DataFrame` 提供了对数据的灵活操作，例如增删行列、过滤、排序、合并和分组等操作。

我们可以通过 `pd.DataFrame()` 构造函数来创建一个 `DataFrame`，传入的数据可以是多种形式（如字典、列表、NumPy 数组等）。

```python
# 构造函数及参数
pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)
```

参数说明：

- **`data`**：`DataFrame` 的数据部分，可以是字典、列表、二维数组、NumPy 数组或另一个 `DataFrame`。不同的数据结构会有不同的默认行为。例如，字典的键作为列名，列表作为行数据。
- **`index`**：`DataFrame` 的行索引。如果不指定，Pandas 会生成从 0 开始的整数索引。
- **`columns`**：`DataFrame` 的列标签。如果不指定，Pandas 会自动使用传入的数据的键（例如字典的键）或从 0 开始的整数索引。
- **`dtype`**：指定 `DataFrame` 的数据类型。可以是 NumPy 数据类型，如果不指定，Pandas 将根据输入数据自动推断。
- **`copy`**：是否复制数据。默认为 `False`，表示不复制。如果设置为 `True`，则会复制输入的数据。

以下是一些简单的创建 `DataFrame` 的示例

![](http://szms-python-images.oss-cn-hangzhou.aliyuncs.com/Pandas/%E5%88%9B%E5%BB%BAdataframe%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.png)

最常见的创建 `DataFrame` 的方法之一是使用字典，其中字典的键将作为列名，值将作为列数据：

```python
import pandas as pd

# 使用字典创建 DataFrame
data = {
    "Name": ["Tom", "Jerry", "Spike"],
    "Age": [28, 22, 25],
    "Score": [85, 92, 78]
}

df = pd.DataFrame(data)

# 输出 DataFrame
print(df)
```

输出：

```shell
    Name  Age  Score
0    Tom   28     85
1  Jerry   22     92
2  Spike   25     78
```

在这个例子中，字典的键 `Name`、`Age` 和 `Score` 成为列名，列表数据成为每列的值。Pandas 自动生成了从 0 开始的整数索引。

除了使用字典，我们还可以使用包含嵌套列表的列表来创建 `DataFrame`，每个嵌套列表代表一行数据：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 使用嵌套列表创建 DataFrame
data = [
    ["Tom", 28, 85],
    ["Jerry", 22, 92],
    ["Spike", 25, 78]
]

df = pd.DataFrame(data, columns=["Name", "Age", "Score"])

# 输出 DataFrame
print(df)
```

::

这里通过 `columns` 参数显式地指定了列名，列表中的每个子列表对应 `DataFrame` 中的一行。

基于 pandas 的灵活性，我们还可以使用 NumPy 数组来创建 DataFrame，这种方法适用于大型数值数据集：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd
import numpy as np

# 使用 NumPy 数组创建 DataFrame
data = np.array([[85, 28], [92, 22], [78, 25]])

df = pd.DataFrame(data, columns=["Score", "Age"], index=["Tom", "Jerry", "Spike"])

# 输出 DataFrame
print(df)
```

::

在这个例子中，我们使用 `index` 参数为 `DataFrame` 的行指定了自定义标签。

最后，如果数据是以字典列表形式存储的（如 JSON），可以直接传入字典列表：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 使用字典列表创建 DataFrame
data = [
    {"Name": "Tom", "Age": 28, "Score": 85},
    {"Name": "Jerry", "Age": 22, "Score": 92},
    {"Name": "Spike", "Age": 25, "Score": 78}
]

df = pd.DataFrame(data)

# 输出 DataFrame
print(df)
```

::

对于 `DataFrame`，有如下常见的操作

1. 访问列：可以通过列名访问特定的列。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建 DataFrame
data = {
    "Name": ["Tom", "Jerry", "Spike"],
    "Age": [28, 22, 25],
    "Score": [85, 92, 78]
}
df = pd.DataFrame(data)

# 访问 Name 列
print(df["Name"])
```

::

2. 添加新列：可以通过赋值语句轻松添加新列。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 添加新列 City
df["City"] = ["NY", "LA", "SF"]

# 输出 DataFrame
print(df)
```

::

3. 删除列：使用 `drop()` 方法删除列。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 删除 Age 列
df_dropped = df.drop("Age", axis=1)

# 输出删除后的 DataFrame
print(df_dropped)
```

::

4. 筛选数据：可以通过条件表达式筛选数据。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 筛选 Score 大于 80 的数据
filtered_df = df[df["Score"] > 80]

# 输出筛选结果
print(filtered_df)
```

::

5. 计算统计信息：`DataFrame` 提供了丰富的统计方法。以下示例展示了如何计算均值和描述性统计信息：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 计算均值
mean_score = df["Score"].mean()
print(f"平均分数: {mean_score}")

# 输出 DataFrame 的描述性统计信息
print(df.describe())
```

::

6. 缺失值处理：可以使用 `isna()` 检查缺失值，并使用 `fillna()` 填充缺失值。以下示例展示了如何处理缺失数据：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 创建包含缺失值的 DataFrame
data_with_na = {
    "Name": ["Tom", "Jerry", "Spike"],
    "Age": [28, None, 25],
    "Score": [85, 92, None]
}
df_with_na = pd.DataFrame(data_with_na)

# 检查缺失值
print(df_with_na.isna())

# 填充缺失值
df_filled = df_with_na.fillna(0)

# 输出填充后的 DataFrame
print(df_filled)
```

::

总之，Pandas `DataFrame` 是一个功能强大且灵活的二维数据结构，广泛应用于各种数据分析任务。无论是处理数值数据、时间序列，还是处理结构化的表格型数据，`DataFrame` 都提供了高效、便捷的操作和处理方法。

### 3. 案例练习

通过下面链接中的案例练习，巩固 Pandas 中的数据结构和基本操作。

[https://www.kaggle.com/code/zhaowenxi/pandas-for-python-1](https://www.kaggle.com/code/zhaowenxi/pandas-for-python-1)

## 三、Pandas 与常见的文件格式

### 1. Pandas 与 CSV

CSV（Comma-Separated Values）是一种常见的文件格式，具有简单、轻量的特点，广泛应用于数据传输和存储。Pandas 是 Python 中用于数据分析和处理的强大工具，可以轻松读取、分析和处理 CSV 文件。本文以一个经典的 `example.csv` 文件为例，展示 Pandas 的常用操作，将下面的数据保存在本地并存储为 .csv 格式，结合代码进行操作。

```csv
ID,Name,Age,Gender,Department,Salary,HireDate,PerformanceScore,City
1,John Smith,28,Male,Sales,50000,2018-05-21,85,New York
2,Mary Johnson,34,Female,HR,62000,2017-03-15,92,Los Angeles
3,James Brown,45,Male,IT,72000,2015-09-30,78,Chicago
4,Patricia Garcia,29,Female,Finance,55000,2019-07-11,88,Houston
5,Robert Martinez,41,Male,Marketing,68000,2016-04-20,80,Miami
6,Linda Anderson,36,Female,Sales,59000,2018-11-12,90,Boston
7,Michael Wilson,38,Male,HR,63000,2017-06-07,86,San Francisco
8,Elizabeth Taylor,30,Female,IT,74000,2019-02-23,75,Dallas
9,David Lee,25,Male,Finance,52000,2020-08-14,82,Austin
10,Barbara Hernandez,32,Female,Marketing,67000,2017-10-19,83,Seattle
11,William Clark,29,Male,Sales,56000,2019-12-01,81,Denver
12,Jennifer Lewis,35,Female,HR,60000,2018-01-27,87,Las Vegas
13,Joseph Walker,40,Male,IT,73000,2015-05-10,76,San Diego
14,Susan Hall,33,Female,Finance,56000,2018-09-18,89,New Orleans
15,Charles Young,50,Male,Marketing,78000,2014-11-05,90,Portland
16,Karen King,26,Female,Sales,48000,2020-02-10,84,Columbus
17,Thomas Wright,37,Male,HR,61000,2016-07-15,82,Charlotte
18,Lisa Scott,31,Female,IT,75000,2019-04-29,74,Detroit
19,Christopher Green,47,Male,Finance,70000,2014-06-19,79,Indianapolis
20,Amy Adams,27,Female,Marketing,53000,2019-01-20,85,Nashville
21,Mark Baker,44,Male,Sales,68000,2015-10-03,88,Jacksonville
22,Sarah Gonzalez,39,Female,HR,62000,2017-08-23,81,Memphis
23,Paul Nelson,33,Male,IT,72000,2016-05-09,77,Fort Worth
24,Donna Mitchell,42,Female,Finance,69000,2016-12-27,91,El Paso
25,Steven Perez,28,Male,Marketing,55000,2020-03-05,80,Milwaukee
26,Nancy Roberts,31,Female,Sales,52000,2019-10-15,86,Baltimore
27,Matthew Turner,46,Male,HR,60000,2014-08-21,82,Louisville
28,Dorothy Phillips,34,Female,IT,76000,2016-01-12,74,Oklahoma City
29,Ronald Campbell,43,Male,Finance,72000,2015-03-19,87,Albuquerque
30,Laura Parker,30,Female,Marketing,57000,2020-06-07,80,Kansas City
```

![](http://szms-python-images.oss-cn-hangzhou.aliyuncs.com/Pandas/csv%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png)

1. 读取 CSV 文件：使用 `pd.read_csv()` 可以将 CSV 文件读取为 Pandas `DataFrame` 对象。

```python
import pandas as pd

# 读取 CSV 文件
df = pd.read_csv('example.csv')

# 显示前几行数据
print(df.to_string())
```

> [!Note]
> `to_string()` 用于打印整个 DataFrame，避免 Pandas 默认仅显示头尾 5 行数据。如果文件较大，不建议使用此方法，因为输出内容可能会非常庞大。

2. 查看头尾指定行：

	- 使用 `head(n)` 显示数据集的前 `n` 行，不指定 `n` 时默认返回前 5 行。
	- 使用 `tail(n)` 显示数据集的后 `n` 行，不指定 `n` 时默认返回最后 5 行。

```python
# 显示前 5 行（默认）
print(df.head())

# 显示前 10 行
print(df.head(10))

# 显示后 5 行（默认）
print(df.tail())

# 显示最后 10 行
print(df.tail(10))

```

3. 获取基本信息：使用 `info()` 方法可以获取数据的基本信息，如列的名称、数据类型、非空值的数量等。

```python
# 获取数据的基本信息
df.info()
```

4. 计算统计信息：`describe()` 方法可以快速获取数值列的统计信息，如均值、标准差、最小值和最大值等。

```python
# 计算数值列的统计信息
print(df.describe())
```

5. 筛选数据：可以根据条件筛选数据，如筛选年龄大于 30 且工资超过 60000 的员工。

```python
filtered_df = df[(df["Age"] > 30) & (df["Salary"] > 60000)]
print(filtered_df)
```

6. 保存修改后的 DataFrame

```python
# 保存为新的 CSV 文件
df.to_csv('example_modified.csv', index=False)
```

### 2. Pandas 与 JSON

Pandas 处理 JSON 数据同样非常高效，它可以将 JSON 数据结构转换为 DataFrame，从而简化复杂的嵌套数据格式。JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，广泛用于 Web 开发和 API 响应中。本文将展示如何使用 Pandas 处理 JSON 数据。

我们以一个包含员工信息的 JSON 数据为例：

```json
[
    {"ID": 1, "Name": "John Smith", "Age": 28, "Gender": "Male", "Department": "Sales", "Salary": 50000, "HireDate": "2018-05-21", "PerformanceScore": 85, "City": "New York"},
    {"ID": 2, "Name": "Mary Johnson", "Age": 34, "Gender": "Female", "Department": "HR", "Salary": 62000, "HireDate": "2017-03-15", "PerformanceScore": 92, "City": "Los Angeles"},
    {"ID": 3, "Name": "James Brown", "Age": 45, "Gender": "Male", "Department": "IT", "Salary": 72000, "HireDate": "2015-09-30", "PerformanceScore": 78, "City": "Chicago"}
]
```

1. 读取 JSON 文件：Pandas 可以使用 `pd.read_json()` 直接读取 JSON 文件。JSON 数据格式支持列表、字典以及更复杂的嵌套结构。

```python
import pandas as pd

# 读取 JSON 文件
df = pd.read_json('example.json')

# 显示数据
print(df.to_string())
```

2. 处理包含嵌套结构的 JSON：JSON 文件可能包含嵌套的结构，Pandas 能够处理这些嵌套的字段。对于深度嵌套的 JSON 结构，通常需要先对嵌套字段展开或者提取成独立的列。

假设 JSON 数据有一个嵌套的 `Address` 字段：

```json
{
    "ID": 1,
    "Name": "John Smith",
    "Age": 28,
    "Address": {"City": "New York", "PostalCode": "10001"},
    "Department": "Sales",
    "Salary": 50000,
    "HireDate": "2018-05-21"
}
```

可以使用 Pandas 的 `json_normalize` 方法来展开嵌套的字段：

```python
import pandas as pd
from pandas import json_normalize

# 嵌套 JSON 数据
data = {
    "ID": 1,
    "Name": "John Smith",
    "Age": 28,
    "Address": {"City": "New York", "PostalCode": "10001"},
    "Department": "Sales",
    "Salary": 50000,
    "HireDate": "2018-05-21"
}

# 使用 json_normalize 展开嵌套字段
df = json_normalize(data)
print(df.to_string())
```

输出结果：

```shell
   ID        Name  Age        Department  Salary    HireDate    Address.City  Address.PostalCode
0   1  John Smith   28           Sales    50000  2018-05-21     New York              10001
```

对于复杂的 JSON 文件，比如来自 API 的多层嵌套的 JSON 数据，`json_normalize` 还可以根据路径展开多个嵌套层。例如，假设 JSON 数据的嵌套层级更多：

```json
{
    "ID": 1,
    "Name": "John Smith",
    "Details": {
        "Age": 28,
        "Address": {
            "City": "New York",
            "PostalCode": "10001"
        }
    },
    "Department": "Sales",
    "Salary": 50000,
    "HireDate": "2018-05-21"
}
```

可以指定路径展开多个嵌套层：

```python
import pandas as pd
from pandas import json_normalize

# 复杂嵌套的 JSON 数据
data = {
    "ID": 1,
    "Name": "John Smith",
    "Details": {
        "Age": 28,
        "Address": {
            "City": "New York",
            "PostalCode": "10001"
        }
    },
    "Department": "Sales",
    "Salary": 50000,
    "HireDate": "2018-05-21"
}

# 展开嵌套层
df = json_normalize(data, sep='_')
print(df.to_string())
```

输出结果：

```shell
   ID        Name  Details_Age  Details_Address_City  Details_Address_PostalCode  Department  Salary    HireDate
0   1  John Smith           28              New York                      10001       Sales   50000  2018-05-21
```

这里我们使用了 `sep='_'` 来控制展开的嵌套字段的名称格式，使 DataFrame 更加清晰易读。

3. 保存 DataFrame 为 JSON：处理完 JSON 数据后，可以将其保存回 JSON 格式。Pandas 提供了 `to_json()` 方法来完成这个任务。

```python
# 将 DataFrame 保存为 JSON 文件
df.to_json('output.json', orient='records', lines=True)
```

- `orient='records'` 指定将每一行输出为一个 JSON 对象。
- `lines=True` 用于输出多行 JSON 文件，每一行都是一个独立的 JSON 记录，适合大数据集的处理。

总之，Pandas 是处理 JSON 数据的强大工具，特别是对于复杂的嵌套 JSON，Pandas 提供了简便的工具来将数据转换为表格格式，便于分析和操作。通过 Pandas，我们可以轻松地读取、处理和存储 JSON 数据，简化数据分析流程。

## 四、Pandas 与数据清洗

数据清洗就是对一些没有用的数据进行处理的过程。在实际操作中，很容易遇见数据缺失、数据格式错误、数据错误或数据重复等等情况。要使得数据分析的结果更加准确，就用对这些没有用的数据进行处理。Pandas 提供了多种功能来帮助清理、检查和修正数据中的问题。

### 1. 空值的处理

在数据清洗的过程中，处理空值是非常常见且基础的任务。Pandas 提供了丰富的方法来查找、统计和处理这些缺失值。下面我们将详细讲解如何有效地使用 Pandas 来处理空值，尤其是在删除空值时的最佳实践。

![](http://szms-python-images.oss-cn-hangzhou.aliyuncs.com/Pandas/%E7%A9%BA%E5%80%BC%E7%9A%84%E5%A4%84%E7%90%86.png)

1. 查找空值：查找数据中的空值，可以使用 `isna()` 或 `isnull()` 方法。这两个方法等效，都会返回一个布尔类型的 DataFrame，其中 `True` 表示该值为空。

```python
import pandas as pd

# 创建包含空值的数据
data = {
    "Name": ["Alice", "Bob", None],
    "Age": [25, None, 30],
    "Salary": [50000, 60000, None]
}
df = pd.DataFrame(data)

# 查找空值
print(df.isna())
```

输出：

```shell
Name    Age  Salary
0  False  False   False
1  False   True   False
2   True  False    True
```

> [!Note]
> 需要注意的是，在某些情况下，空值并不仅仅表现为标准的 `NaN`，还可能以其他形式出现，比如 `"n/a"` 或 `"--"`. Pandas 提供了 `na_values` 参数，使我们可以在读取数据时指定这些自定义的空值类型。
> ```python
> # 自定义空值形式
> missing_values = ["n/a", "na", "--"]
> df = pd.read_csv('example.csv', na_values=missing_values)
> ```

2. 统计空值：可以结合 `isna()` 和 `sum()` 方法来统计每列中空值的数量。`isna()` 返回的布尔值可以通过 `sum()` 汇总，显示每列中缺失值的个数。

```python
# 统计每列的空值数量
print(df.isna().sum())
```

输出：

```shell
Name      1
Age       1
Salary    1
dtype: int64
```

3. 删除空值：在处理空值时，删除包含空值的行或列是常见的操作，尤其当缺失的数据比例较大时。这时可以使用 `dropna()` 方法来删除空值。`dropna()` 提供了多种灵活的参数，可以根据具体需求决定是删除整行还是整列，或是仅在某些特定条件下删除。

```python
# 语法：
DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)
```

参数说明：

- `axis`：指定删除的方向。默认为 `0`，即删除包含空值的整行；若设置为 `1`，则删除包含空值的整列。
- `how`：指定删除的条件。默认值为 `'any'`，即只要一行或一列中有一个空值就删除；若设置为 `'all'`，则仅当一行或一列所有值都为空时才删除。
- `thresh`：设置一个阈值，要求该行或列至少有 `thresh` 个非空值，才能保留下来。例如，如果 `thresh=2`，表示保留至少有两个非空值的行或列。
- `subset`：指定需要检查空值的列。如果只需要检查特定列，可以通过传入列名列表实现。
- `inplace`：如果设置为 `True`，删除操作将在原 DataFrame 上执行，并且不返回新对象；如果为 `False`（默认值），则会返回一个新的 DataFrame。

将下面的例子多次分开运行，查看其与原 `DataFrame` 的对比：

```python
# 删除包含任何空值的行
df_cleaned = df.dropna()
print(df_cleaned)

# 删除只在 'Name' 和 'Age' 列有空值的行
df_cleaned_subset = df.dropna(subset=['Name', 'Age'])
print(df_cleaned_subset)

# 只删除包含全部为空的行
df_cleaned_all = df.dropna(how='all')
print(df_cleaned_all)

# 保留至少有两项非空值的行
df_thresh = df.dropna(thresh=2)
print(df_thresh)
```

输出：

```shell
# 原 DataFrame
Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob   NaN  60000.0
2   None  30.0      NaN

# 删除包含任何空值的行：
    Name   Age   Salary
0  Alice  25.0  50000.0

# 删除只在 'Name' 和 'Age' 列有空值的行：
    Name   Age   Salary
0  Alice  25.0  50000.0

# 只删除包含全部为空的行：
    Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob   NaN  60000.0
2   None  30.0      NaN

# 保留至少有两项非空值的行：
    Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob   NaN  60000.0
```

4. 填充空值：有时我们并不想删除数据，而是通过填充的方式保留尽可能多的信息。`fillna()` 方法可以用来填充空值，常见的填充策略包括用固定值、均值、中位数或前后邻近值进行填充。

```python
# 用 0 填充所有空值
df_filled_zero = df.fillna(0)
print(df_filled_zero)

# 用前一个有效值填充空值（即向前填充）
df_filled_ffill = df.fillna(method='ffill')
print(df_filled_ffill)

# 用后一个有效值填充空值（即向后填充）
df_filled_bfill = df.fillna(method='bfill')
print(df_filled_bfill)

# 用每列的均值填充空值（以 'Age' 列为例）
df['Age'] = df['Age'].fillna(df['Age'].mean())
print(df)
```

将以上代码分开运行，其结果分别如下：

```shell
# 原 DataFrame
Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob   NaN  60000.0
2   None  30.0      NaN

# 用 0 填充所有空值:
    Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob   0.0  60000.0
2      0  30.0      0.0

# 用AGE列的均值填充该列空值:
Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob  27.5  60000.0
2   None  30.0      NaN

# 用前一个有效值填充空值:
    Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob  25.0  60000.0
2    Bob  30.0  60000.0

# 用后一个有效值填充空值:
    Name   Age   Salary
0  Alice  25.0  50000.0
1    Bob  30.0  60000.0
2   None  30.0      NaN
```

Pandas 为处理空值提供了强大的功能，包括查找、统计、删除和填充。在数据清洗中，选择合适的空值处理方式取决于数据的具体情况。通过合理使用 `dropna()` 和 `fillna()`，可以有效地保持数据的完整性和分析结果的准确性。

### 2. 重复值的处理

重复数据可能会导致分析结果的偏差，因此需要对数据进行去重处理。

![](http://szms-python-images.oss-cn-hangzhou.aliyuncs.com/Pandas/%E9%87%8D%E5%A4%8D%E5%80%BC%E7%9A%84%E5%A4%84%E7%90%86.png)

1. 查找重复数据：可以使用 `duplicated()` 方法查找重复的数据。该方法返回一个布尔序列，指示每一行是否为重复项。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建一个示例 DataFrame
data = {
    'Name': ['Alice', 'Bob', 'Alice', 'David', 'Bob'],
    'Age': [25, 30, 25, 35, 30],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles']
}
df = pd.DataFrame(data)

# 查找重复的行
print(df.duplicated())
```

::

2. 删除重复数据：可以使用 `drop_duplicates()` 方法删除重复的行。通过 `subset` 参数，可以指定要检查重复的列。如果不指定，则对所有列进行检查。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 删除重复的行
df_unique = df.drop_duplicates()
print(df_unique)

# 仅基于 'Name' 列删除重复行
df_unique_name = df.drop_duplicates(subset=['Name'])
print(df_unique_name)
```

::

### 3. 转换数据类型

有时候，数据可能存在错误的数据类型，比如年龄字段被存储为字符串类型。可以使用 `astype()` 方法将列转换为正确的数据类型。

```python
import pandas as pd

# 创建一个示例 DataFrame
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': ['25', '30', '35', '40'],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']
}
df = pd.DataFrame(data)

# 将 'Age' 列转换为整数类型
df['Age'] = df['Age'].astype(int)

# 查看 DataFrame 的数据类型
print(df.dtypes)
```

输出：

```shell
Name    object
Age      int64
City    object
dtype: object
```

有时候，数据类型可能是正确的，但数据的格式不正确，如某日期列存放了多种格式的日期数据，我们可以使用 `to_datetime` 和 `strftime` 将格式统一：

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建一个DataFrame，包含多种日期格式
data = {'日期': ['2023-01-01 12:34:56', '2023/02/02', '03/04/2023', '2023-05-06T10:11:12Z']}
df = pd.DataFrame(data)

# 使用to_datetime()函数，指定错误处理方式为coerce，并尝试多种常见日期格式
df['日期'] = pd.to_datetime(df['日期'], errors='coerce', infer_datetime_format=True)

# 将日期格式统一为"YYYY-MM-DD"
df['日期'] = df['日期'].dt.strftime('%Y-%m-%d')

print(df)
```

::

### 5. 数据标准化

为了保证数据的标准化，可以将字符串字段统一转换为小写或大写，或去除多余的空格。

```python
import pandas as pd

# 创建一个示例 DataFrame
data = {
    'Name': [' Alice ', 'Bob', ' CHARLIE ', 'David '],
    'Age': [25, 30, 35, 40],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']
}
df = pd.DataFrame(data)

# 将 'Name' 列统一转换为小写
df['Name'] = df['Name'].str.lower()

# 去除 'Name' 列中的多余空格
df['Name'] = df['Name'].str.strip()

# 输出处理后的 DataFrame
print(df)
```

```shell
Name  Age         City
0    alice   25     New York
1      bob   30  Los Angeles
2  charlie   35      Chicago
3    david   40      Houston
```

### 6. 案例练习

跟着下面链接中的案例，回顾本章节的内容：

[https://www.kaggle.com/code/zhaowenxi/pandas-for-python-2](https://www.kaggle.com/code/zhaowenxi/pandas-for-python-2)

假设有一个包含员工信息的DataFrame `df`，其初始状态如下所示：

| Name   | Age | Salary | City       |
|--------|-----|--------|------------|
| Alice  | 25  | 50000  | New York   |
| Bob    | NaN | 60000  | Los Angeles|
| NULL   | 30  | NaN     | Chicago    |
| Alice  | 25  | 50000  | New York   |
| David  | 35  | 65000  | Houston    |

需要执行以下数据清洗任务：

1. **查找和统计空值**：
   - 使用 `isna()` 方法查找DataFrame中的空值，并打印结果。
   - 使用 `sum()` 方法统计每列中空值的数量，并打印结果。

2. **处理空值**：
   - 删除包含任何空值的行，并打印结果。
   - 删除只在 `Name` 和 `Age` 列有空值的行，并打印结果。
   - 保留至少有两项非空值的行，并打印结果。
   - 用每列的均值填充空值（以 `Age` 列为例），并打印结果。

3. **处理重复值**：
   - 查找并打印所有重复的行。
   - 删除所有重复的行，并打印结果。
   - 仅基于 `Name` 列删除重复行，并打印结果。

4. **转换数据类型**：
   - 将 `Age` 列的数据类型从字符串转换为整数，并打印数据类型转换后的结果。

5. **统一日期格式**：
   - 假设 `City` 列中包含了多种日期格式的数据，使用 `to_datetime` 函数将日期统一为ISO格式（YYYY-MM-DD），并打印结果。

6. **数据标准化**：
   - 将 `Name` 列中的字符串统一转换为小写，并去除多余的空格，然后打印处理后的DataFrame。

## 五、Pandas 常用函数总结

### 1. 数据的读取、查看以及清洗

在上面的文章中，我们了解了 Pandas 最基础的函数：

| 函数                                    | 说明                            |
| ------------------------------------- | ----------------------------- |
| pd.read_csv(filename)                 | 读取 CSV 文件；                    |
| pd.read_excel(filename)               | 读取 Excel 文件；                  |
| pd.read_sql(query, connection_object) | 从 SQL 数据库读取数据；                |
| pd.read_json(json_string)             | 从 JSON 字符串中读取数据；              |
| pd.read_html(url)                     | 从 HTML 页面中读取数据。               |
| df.head(n)                            | 显示前 n 行数据；                    |
| df.tail(n)                            | 显示后 n 行数据；                    |
| df.info()                             | 显示数据的信息，包括列名、数据类型、缺失值等；       |
| df.describe()                         | 显示数据的基本统计信息，包括均值、方差、最大值、最小值等； |
| df.shape                              | 显示数据的行数和列数。                   |
| df.dropna()                           | 删除包含缺失值的行或列；                  |
| df.fillna(value)                      | 将缺失值替换为指定的值；                  |
| df.replace(old_value, new_value)      | 将指定值替换为新值；                    |
| df.duplicated()                       | 检查是否有重复的数据；                   |
| df.drop_duplicates()                  | 删除重复的数据。                      |

### 2. 数据选择和切片

1. 通过列名直接获取该列数据：`df[column_name]`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建一个DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 28]}
df = pd.DataFrame(data)

# 选择'Age'列
age_column = df['Age']
print(age_column)
```

::

2. 通过标签选择数据：`df.loc[row_index, column_name]`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 选择第一行，'Name'列
first_name = df.loc[0, 'Name']
print(first_name)
```

::

3. 通过索引选择数据：`df.iloc[row_index, column_index]`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 选择第二行，第一列（索引从0开始）
second_row_first_column = df.iloc[1, 0]
print(second_row_first_column)
```

::

4. 通过列名列表选择多个列：`df.filter(items=[column_name1, column_name2])`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 选择'Name'和'Age'两列
selected_columns = df.filter(items=['Name', 'Age'])
print(selected_columns)
```

::

5. 使用正则表达式匹配列：`df.filter(regex='regex')`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 选择所有包含'Age'的列
age_related_columns = df.filter(regex='Age')
print(age_related_columns)
```

::

6. 随机选择 n 行数据：`df.sample(n)`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 随机抽取2行数据
sample_df = df.sample(2)
print(sample_df)
```

::

### 3. 数据排序

1. 根据指定列的值对 `DataFrame` 进行排序：

```python
DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')
```

参数解释：

- `by`: 要排序的列名或列名列表。
- `axis`: 排序的轴，0表示按行排序，1表示按列排序。
- `ascending`: 是否升序排序，默认为True。
- `inplace`: 是否在原DataFrame上修改，默认为False。
- `kind`: 排序算法，常用的有'quicksort', 'mergesort', 'heapsort'。
- `na_position`: 指定缺失值的排序位置，'first'表示放在前面，'last'表示放在后面。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建一个DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 28]}
df = pd.DataFrame(data)

# 按照'Age'列升序排序
df_sorted_by_age = df.sort_values('Age')
print(f"按照'Age'列升序排序:\n{df_sorted_by_age}")

# 按照'Name'列降序排序
df_sorted_by_name_desc = df.sort_values('Name', ascending=False)
print(f"按照'Name'列降序排序:\n{df_sorted_by_name_desc}")

# 按照多个列排序，'Age'升序，'Name'降序
df_sorted_multi = df.sort_values(['Age', 'Name'], ascending=[True, False])
print(f"按照多个列排序，'Age'升序，'Name'降序:\n{df_sorted_multi}")
```

::

2. 根据索引进行排序

```python
DataFrame.sort_index(axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')
```

参数解释：

- `axis`: 排序的轴，0 表示按行排序，1 表示按列排序。
- `ascending`: 是否升序排序，默认为 True。
- `inplace`: 是否在原 DataFrame 上修改，默认为 False。
- `kind`: 排序算法，常用的有'quicksort', 'mergesort', 'heapsort'。
- `na_position`: 指定缺失值的排序位置，'first'表示放在前面，'last'表示放在后面。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 创建一个DataFrame，索引为字符串
data = {'A': [1, 2, 3], 'B': [4, 5, 6]}
df = pd.DataFrame(data, index=['c', 'a', 'b'])

# 按照索引升序排序
df_sorted_by_index = df.sort_index()
print(df_sorted_by_index)
```

::

### 4. 数据分组和聚合

1. 对数据按照指定列进行分组：`df.groupby(column_name)`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
import pandas as pd

# 创建一个DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie', 'Alice'], 'Age': [25, 30, 28, 25], 'City': ['New York', 'Los Angeles', 'Chicago', 'New York']}
df = pd.DataFrame(data)

# 按照'City'列分组
grouped = df.groupby('City')

# 对每个分组计算平均年龄
print(grouped['Age'].mean())
```

::

2. 对分组后的数据应用聚合函数：`df.aggregate({column_name:[function_name]})`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 对上面的分组结果求平均值、最大值
print(grouped.aggregate({'Age': ['mean', 'max']}))
```

::

3. 生成透视表

```python
DataFrame.pivot_table(values, index, columns, aggfunc)
```

参数解释：

- `values`：要聚合的值列。
- `index`：行索引列。
- `columns`：列索引列。
- `aggfunc`：聚合函数。

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 生成一个透视表，按城市和年龄分组，计算每个分组的人数
pivot_table = df.pivot_table(values='Name', index='City', columns='Age', aggfunc='count')
print(pivot_table)
```

::

### 5. 数据合并

1. 将多个数据框按照行或列进行合并：`pd.concat([df1, df2])`

```python
# 创建两个DataFrame
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

# 按行合并
df_concat_rows = pd.concat([df1, df2])
print(df_concat_rows)

# 按列合并
df_concat_cols = pd.concat([df1, df2], axis=1)
print(df_concat_cols)
```

输出：

```shell
# 按行合并:
   A  B
0  1  3
1  2  4
0  5  7
1  6  8
# 按列合并:
   A  B  A  B
0  1  3  5  7
1  2  4  6  8
```

2. 根据指定列将两个DataFrame进行合并，类似于SQL中的JOIN操作：`pd.merge(df1, df2, on=column_name)`

```python
# 创建两个DataFrame，有一个公共列'Name'
df1 = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})
df2 = pd.DataFrame({'Name': ['Alice', 'Charlie'], 'City': ['New York', 'Chicago']})

# 按'Name'列合并
df_merged = pd.merge(df1, df2, on='Name')
print(df_merged)
```

输出：

```shell
Name  Age      City
0  Alice   25  New York
```

### 6. 数据选择和过滤

1. 条件筛选：`df[df['column_name'] > value]`

```python
import pandas as pd

# 创建一个示例 DataFrame
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 40],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago']
}
df = pd.DataFrame(data)

# 条件筛选：选择年龄大于25的人
df_filtered = df[df['Age'] > 25]
print(df_filtered)
```

输出：

```shell
Name  Age         City
1      Bob   30  Los Angeles
2  Charlie   35     New York
3    David   40      Chicago
```

2. 使用字符串表达式选择列中满足条件的行：`df.query('column_name > value')`

::code-mirror-run{:editable="true" maxHeight="20rem" :showInCol="true"}

```python
# 使用字符串表达式选择列中满足条件的行：选择年龄大于25且来自纽约的人
df_filtered_query = df.query('Age > 25 and City == "New York"')
print(df_filtered_query)
```

::

### 7. 案例练习

通过以下案例练习，来熟悉本章中提及的重要函数：

[https://www.kaggle.com/code/zhaowenxi/pandas-for-python-3](https://www.kaggle.com/code/zhaowenxi/pandas-for-python-3)

假设你手头有一份员工数据集，包含员工的姓名、年龄、城市和部门信息。您的任务是使用Pandas库对这份数据进行一系列的处理操作。以下是数据集的初始状态：

| Name    | Age | City        | Department |
|---------|-----|-------------|------------|
| Alice   | 25  | New York    | HR         |
| Bob     | 30  | Los Angeles | Sales      |
| Charlie | 28  | Chicago     | IT         |
| David   | 40  | Chicago     | IT         |
| Alice   | 25  | New York    | HR         |

请根据以下要求完成部分数据处理任务：

1. **数据读取与查看**：
   - 读取上述数据集，并创建DataFrame `df`。
   - 使用 `head()` 方法查看数据集的前两行。

2. **数据清洗**：
   - 使用 `dropna()` 方法删除包含缺失值的行。
   - 使用 `fillna()` 方法将所有缺失的年龄值替换为年龄列的均值。

3. **数据选择和切片**：
   - 通过列名直接获取“Age”列的数据。
   - 使用 `loc` 选择第二行的“Name”列数据。

4. **数据排序**：
   - 按照“Age”列升序排序，并打印结果。

5. **数据分组和聚合**：
   - 按照“City”列对数据进行分组，并计算每个城市的员工平均年龄。

6. **数据合并**：
   - 假设有另一个DataFrame `df_departments`，包含部门的预算信息，如下所示：
     ```
     Department  Budget
     HR          10000
     Sales       20000
     IT          15000
     ```
   - 使用 `merge()` 方法将 `df` 和 `df_departments` 按照“Department”列合并，并打印结果。
